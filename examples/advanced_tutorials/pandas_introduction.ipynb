{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example Workflow with Sina and Pandas\n",
    "=================================\n",
    "\n",
    "This is a sample Jupyter notebook that introduces users to a workflow using Sina with pandas. It uses the Fukushima data set found in the Sina examples folder. The get_pd() function itself is not tied to any particular data set, and lends itself well to a variety of data needs.\n",
    "\n",
    "Note: The typical Sina dependencies do not include all of the libraries required to run this notebook. If you typically use the LC Sina virtual environment, follow either the standard or manual set up instructions from the Readme in the sina/python/ folder. Once your virtual environment is set up, you can add the additional libraries by using pip.\n",
    "\n",
    "#### Additional Required Packages:\n",
    "\n",
    "pandas\n",
    "\n",
    "sklearn\n",
    "\n",
    "#### Eaxmple:\n",
    "pip install pandas sklearn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to Sina\n",
    "Connect to Sina as you usually do. Consult Sina documentation for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sina.datastore import create_datastore\n",
    "import sina.utils\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Initialization\n",
    "\n",
    "# Access the data\n",
    "database = sina.utils.get_example_path('fukushima/data.sqlite')\n",
    "print('Using database {}'.format(database))\n",
    "ds = create_datastore(database)\n",
    "\n",
    "\n",
    "# Make a phantom call to plt.show() to work around a known Jupyter issue with displaying graphs\n",
    "plt.show()\n",
    "\n",
    "print(\"Connection to database made. Ready to proceed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Declare Pandas Conversion Function\n",
    "\n",
    "This function is the main interface between pandas and Sina. Feel free to copy/modify this function for use within your own workflow. Note that this function does drop units without doing any conversions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# makes printing a little bit prettier, shows less rows\n",
    "pd.options.display.max_rows = 10\n",
    "\n",
    "\n",
    "def get_pd(ds, ids, fields=None):\n",
    "    '''\n",
    "    Get a pandas dataframe for the given IDs.\n",
    "    \n",
    "    Uses a global records to interact with sina.\n",
    "    ...\n",
    "    \n",
    "    :param ds: the datastore the records are coming from\n",
    "    :param ids: the list of IDs of the records to include in the dataframe\n",
    "    :param fields: list of data elements ie column names for dataframe\n",
    "    \n",
    "    :raises Exception: Error with list of ids \n",
    "    \n",
    "    :returns: dataframe with rows corresponding to IDs and collumns corresponding to fields\n",
    "    '''\n",
    "    \n",
    "    # ensure that there is a list of IDs\n",
    "    try:\n",
    "        ids = list(ids)\n",
    "        \n",
    "    except:\n",
    "        raise Exception('Something went wrong with IDs')\n",
    "\n",
    "    # if not specified, get all data field names\n",
    "    if not fields:\n",
    "        fields = ds.records.get(ids[0]).data.keys()\n",
    "        \n",
    "        \n",
    "    # get the full record objects for all ids\n",
    "    records = ds.records.get(ids)\n",
    "    \n",
    "    # turn list of records into a list of lists containg the data values\n",
    "    recs = []\n",
    "    for record in records:\n",
    "        entry = []\n",
    "        for field in fields:\n",
    "            entry.append(record.data[field]['value'])\n",
    "        recs.append(entry)\n",
    "         \n",
    "    return pd.DataFrame(data=recs, columns=fields)\n",
    "\n",
    "print('Pandas Function Declared')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing our Pandas Conversion Function\n",
    "After runnning this cell, you will find that all records of type 'obs' will be loaded into a data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get ids for all observations\n",
    "ids = ds.records.find_with_type(\"obs\", ids_only=True)\n",
    "\n",
    "# convert to pandas data frame\n",
    "df = get_pd(ds,ids)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demonstrating a query before pandas conversion \n",
    "\n",
    "### Selecting Specific Records\n",
    "You can use sina to query for data to fall within certain values, then turn all of the resulting records into a dataframe. The cell bellow builds a df with all records where the  date is 4/18/2011. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run query and get ids\n",
    "ids = ds.records.find_with_data(date='4/18/2011')\n",
    "\n",
    "# convert to pandas data frame\n",
    "df = get_pd(ds,ids)\n",
    "\n",
    "# print and review\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering by Data Values\n",
    "You can use Sina to query for data to fall within certain values, then turn all of the resulting records into a dataframe. In this example, we will use the fields option so that our data frame only contains the data fields altitude, longitude, latitude and gcnorm. The cell below builds a df with all records where alt_hae is between 250 and 300. This uses one of Sina's special query functions, DataRange, see query documentation for more deatils. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# required for DataRange function\n",
    "from sina.utils import DataRange\n",
    "\n",
    "# run query and get ids\n",
    "ids = ds.records.find_with_data(alt_hae=DataRange(250,300))\n",
    "\n",
    "# specify which fields you want\n",
    "fields = ['alt_hae', 'gcnorm', 'latitude', 'longitude']\n",
    "\n",
    "# convert to pandas data frame\n",
    "df = get_pd(ds,ids, fields)\n",
    "\n",
    "# print and review\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing Data with Panda\n",
    "This is a quick demonstration of how to access your data once it is in a data frame. In general, you access columns of data rather than individual records.\n",
    "\n",
    "### Getting a Single Column\n",
    "A single column from a dataframe is a pandas series. Note that there is no column name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "\n",
    "# get ids for all observations\n",
    "ids = list(ds.records.find_with_type(\"obs\", ids_only=True))\n",
    "\n",
    "# we will use a random subset of records, no need to load them all for these examples\n",
    "k = 1000\n",
    "ids = random.sample(ids, k)\n",
    "\n",
    "# convert to pandas data frame\n",
    "df = get_pd(ds,ids)\n",
    "\n",
    "# getting a single column\n",
    "altitude = df['alt_hae']\n",
    "print(altitude)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting a Subset of Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting a subset of columns\n",
    "cols = ['latitude', 'longitude']\n",
    "coordinates = df[cols]\n",
    "print(coordinates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modifying an Existing Column\n",
    "You can modify all values in an existing column by some constant using this systanx. See Pandas documentation for more details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modifying an existing column\n",
    "new_sea_level=5\n",
    "df['alt_hae'] = df['alt_hae'] - new_sea_level\n",
    "print(df['alt_hae'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting a Subset of Records\n",
    "You can filter down records based on their values for specific columns. See Pandas documentation for more details. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting a subset of records\n",
    "new_df = df[df['date']=='4/5/2011']\n",
    "print(new_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting a Random Sample of Records\n",
    "Example for getting random samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a random subset of records, in this case 5\n",
    "random_df = df.sample(n=5)\n",
    "print(random_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Max  Values\n",
    "Example of getting max values from pandas df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get k largest gcnorm values\n",
    "k = 5\n",
    "klarge = df.nlargest(k, 'gcnorm')\n",
    "print(\"Here are the {} largest values for gcnorm:\\n\".format(k))\n",
    "print(klarge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Min Values\n",
    "Example of getting max values from pandas df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get k smallest altitude values\n",
    "k = 5\n",
    "ksmall = df.nsmallest(k, 'alt_hae')\n",
    "print(\"Here are the {} smallest values for altitude:\\n\".format(k))\n",
    "print(ksmall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Manipulation and Plotting\n",
    "### Finding Distance\n",
    "Here we will use longitude and latitude coordinates to find the distance from the reactor, then plot the gcnorm against that distance. The haversine function below is used to demonstrate vectorized operations with pandas. In general, you should not use a for loop to modify/create data. For more information, review pandas documentation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# note that we use the numpy library, this allows us to vectorize our code. \n",
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    '''\n",
    "    Get distance (km) between two points on the surface of a sphere (Earth).\n",
    "    ...\n",
    "    \n",
    "    :param lat1: the latitude value of the first point\n",
    "    :param lon1: the longitude value of the first point\n",
    "    :param lat2: the latitude value of the second point\n",
    "    :param lon2: the longitude value of the second point\n",
    "    \n",
    "    :returns: distance (km) between the two points\n",
    "    '''\n",
    "    \n",
    "    Radius_Earth_KM = 6371\n",
    "    lat1, lon1, lat2, lon2 = map(np.deg2rad, [lat1, lon1, lat2, lon2])\n",
    "    dlat = lat2 - lat1 \n",
    "    dlon = lon2 - lon1 \n",
    "    a = np.sin(dlat/2)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2)**2\n",
    "    c = 2 * np.arcsin(np.sqrt(a)) \n",
    "    total_km = Radius_Earth_KM * c\n",
    "    return total_km\n",
    "\n",
    "# get ids for all observations\n",
    "ids = list(ds.records.find_with_type(\"obs\", ids_only=True))\n",
    "\n",
    "# convert to pandas data frame\n",
    "df = get_pd(ds,ids)\n",
    "\n",
    "# making a new column using existing columns. \n",
    "reactor = [37.4227,141.0327 ]\n",
    "df['distance'] = haversine(df['longitude'], df['latitude'], reactor[1], reactor[0])\n",
    "\n",
    "\n",
    "# Now that we have the distance, we want to plot by date.\n",
    "dates = df['date'].unique()\n",
    "for date in dates:\n",
    "    plot_df = df[df['date']==date]\n",
    "    x = plot_df['distance']\n",
    "    y = plot_df['gcnorm']\n",
    "    fig = plt.figure()\n",
    "    ax = plt.axes()\n",
    "    ax.plot(x,y)\n",
    "    ax.set_xlabel(\"Distance from reactor (km)\")\n",
    "    ax.set_ylabel(\"Normalized Gross Counts per Second\")\n",
    "    ax.set_title('GCNorm over Distance for date {}'.format(date))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3D Plots with Pandas\n",
    "Here, we will demonstrate how to produce a 3D plot using data from a DataFrame and matplot lib. Note that this plot interpolates the surface by creating triangles with adjacent points. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits import mplot3d\n",
    "\n",
    "# get ids for a single date\n",
    "ids = ds.records.find_with_data(date='4/18/2011')\n",
    "\n",
    "\n",
    "# convert to pandas data frame\n",
    "df = get_pd(ds,ids)\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = plt.axes(projection='3d')\n",
    "\n",
    "\n",
    "x = df['longitude']\n",
    "y = df['latitude']\n",
    "z = df['gcnorm']\n",
    "_ = ax.plot_trisurf(x, y, z, cmap='inferno', edgecolor='none')\n",
    "_ = ax.set_title('Heat Map by Latitude and longitude')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining Concepts\n",
    "By combining concepts from the last two cells, we can create a heat map that includes both distance from the reactor and altitude. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# get ids for all observations\n",
    "ids = list(ds.records.find_with_type(\"obs\", ids_only=True))\n",
    "\n",
    "# we will use a random subset of records, no need to load them all for these examples\n",
    "k = 15000\n",
    "ids = random.sample(ids, k)\n",
    "\n",
    "# convert to pandas data frame\n",
    "df = get_pd(ds,ids)\n",
    "\n",
    "# making a new column using existing columns. \n",
    "reactor = [37.4227,141.0327 ]\n",
    "\n",
    "#haversine function declared above\n",
    "df['distance'] = haversine(df['longitude'], df['latitude'], reactor[1], reactor[0])\n",
    "\n",
    "\n",
    "# Now that we have the distance, we want to plot by date.\n",
    "dates = df['date'].unique()\n",
    "for date in dates:\n",
    "    plot_df = df[df['date']==date]\n",
    "    x = plot_df['distance']\n",
    "    z = plot_df['gcnorm']\n",
    "    y = plot_df['alt_hae']\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    ax = plt.axes(projection='3d')\n",
    "    \n",
    "    _ = ax.plot_trisurf(x, y, z, cmap='inferno', edgecolor='none')\n",
    "    _ = ax.set_xlabel(\"Distance from reactor (km)\")\n",
    "    _ = ax.set_ylabel(\"Altitude HAE\")\n",
    "    _ = ax.set_zlabel(\"Normalized Gross Counts per Second\")\n",
    "    _ = ax.set_title('GCNorm over Distance and Altitude for date {}'.format(date))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example with Outlier Detection and Removal\n",
    "A basic example of outlier detection and removal using the zscore method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import zscore\n",
    "import numpy as np\n",
    "\n",
    "def remove_outliers(features, target):\n",
    "    '''\n",
    "    Uses Z-score to identify outliers.\n",
    "    ...\n",
    "    :param features: DataFrame with only numeric values\n",
    "    :param target: DataFrame with remaining columns\n",
    "    \n",
    "    :returns: Dataframe without outliers\n",
    "    '''\n",
    "    \n",
    "    z = np.abs(zscore(features))\n",
    "    \n",
    "    df = pd.concat([features, target], axis = 1)\n",
    "    \n",
    "    return df[(z <3).all(axis=1)]\n",
    "\n",
    "\n",
    "# get ids for all observations\n",
    "ids = list(ds.records.find_with_data(date='4/5/2011'))\n",
    "\n",
    "# convert to pandas data frame\n",
    "df = get_pd(ds,ids)\n",
    "# only select numeric types as your features\n",
    "features = df.select_dtypes(exclude='object')\n",
    "\n",
    "# get non-numeric types\n",
    "targets = df.select_dtypes(include='object')\n",
    "\n",
    "new_df = remove_outliers(features, targets)\n",
    "\n",
    "# plot results, maybe be more useful with other data sets\n",
    "fig = plt.figure()\n",
    "ax = plt.axes(projection='3d')\n",
    "\n",
    "x = df['longitude']\n",
    "y = df['latitude']\n",
    "z = df['gcnorm']\n",
    "_ = ax.plot_trisurf(x, y, z, cmap='inferno', edgecolor='none')\n",
    "_ = ax.set_title('Heat Map by Latitude and longitude (Original)')\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = plt.axes(projection='3d')\n",
    "\n",
    "x = new_df['longitude']\n",
    "y = new_df['latitude']\n",
    "z = new_df['gcnorm']\n",
    "_ = ax.plot_trisurf(x, y, z, cmap='inferno', edgecolor='none')\n",
    "_ = ax.set_title('Heat Map by Latitude and longitude (Outliers Removed)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example with Linear Regresion\n",
    "This example shows some use with linear regression. Here, we do some feature engineering, train a model, and view the results. The goal for the model is to be able to determine gcnorm based on distance from the reactor, altitude, and days since the event. This model does not perform particularily well, but does serve as an example workflow with pandas and sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# load data from sina\n",
    "\n",
    "# get ids for all observations\n",
    "ids = list(ds.records.find_with_type(\"obs\", ids_only=True))\n",
    "\n",
    "# we will use a random subset of records, no need to load them all for this example\n",
    "k = 5000\n",
    "ids = random.sample(ids, k)\n",
    "\n",
    "# convert to pandas data frame\n",
    "df = get_pd(ds,ids)\n",
    "\n",
    "# feature engineering\n",
    "\n",
    "# use haversine function declared in above cells to get distance measure\n",
    "reactor = [37.4227,141.0327 ]\n",
    "df['distance'] = haversine(df['longitude'], df['latitude'], reactor[1], reactor[0])\n",
    "\n",
    "# calculate days since reactor disaster\n",
    "# use a dictionary to map strings to ints, using the df.replace() method\n",
    "dates = {'4/5/2011':24, '4/18/2011':37, '5/9/2011':58}\n",
    "df['days_since'] = df['date'].replace(dates)\n",
    "\n",
    "# train the model\n",
    "\n",
    "# our 3 features are altitude, distance, days\n",
    "feature_labels = ['alt_hae', 'distance', 'days_since']\n",
    "\n",
    "# get features vector, and concatentate. x, x^2, x^3\n",
    "X = df[feature_labels].values\n",
    "for i in range(2,4):\n",
    "    X = np.concatenate((X, X**i), axis=1)\n",
    "    \n",
    "# get labels    \n",
    "Y = df['gcnorm'].values\n",
    "\n",
    "\n",
    "# fit the regression\n",
    "reg = LinearRegression().fit(X, Y)\n",
    "\n",
    "\n",
    "# view the results \n",
    "zprime = reg.predict(X)\n",
    "\n",
    "y = df['days_since']\n",
    "x = df['distance']\n",
    "z = df['gcnorm']\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = plt.axes(projection='3d')\n",
    "_ = ax.plot_trisurf(x, y, z, cmap='inferno', edgecolor='none')\n",
    "_ = ax.set_title('Recorded Heat Map')\n",
    "_ = ax.set_ylabel('Days since Event')\n",
    "_ = ax.set_xlabel('Distance from reactor')\n",
    "_ = ax.set_zlabel('GCNorm')\n",
    "\n",
    "print('\\n\\n')\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = plt.axes(projection='3d')\n",
    "_ = ax.plot_trisurf(x, y, zprime, cmap='inferno', edgecolor='none')\n",
    "_ = ax.set_title('Predicted Heat Map')\n",
    "_ = ax.set_ylabel('Days since Event')\n",
    "_ = ax.set_xlabel('Distance from reactor')\n",
    "_ = ax.set_zlabel('GCNorm')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factory.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
