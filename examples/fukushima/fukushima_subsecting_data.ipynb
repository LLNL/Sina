{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fukushima Heatmap: Subsecting Data\n",
    "===============================\n",
    "In some cases, the amount of data available is too much to graph all at once. While the Fukushima set is small enough to fit comfortably in memory, we can still use it to showcase some techniques for handling much larger sets. In this case, we will still process the entire set of data, but do so in coordinate cells; each cell is averaged to create a heatmap. You can configure the number of cells created; the more there are, the less data is held in memory at a time, but the more queries are done overall.\n",
    "\n",
    "\n",
    "Setting number of cells and opening a connection\n",
    "-----------------------------------------------------------\n",
    "\n",
    "As mentioned above, we choose a number of cells that's a reasonable compromise between amount of data in memory and amount of querying needing done (also, a higher number of cells will naturally give a graph with greater fidelity). We then open a connection to our database of interest, and find what dates are available to us. We'll track data from each date separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from IPython.display import clear_output, display\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import patheffects\n",
    "import numpy as np\n",
    "import sina.datastores.sql as sina_sql\n",
    "from sina.utils import get_example_path, DataRange\n",
    "\n",
    "# Number of cells along a side; this number squared is the total number of cells\n",
    "CELLS_PER_SIDE = 12\n",
    "\n",
    "database = get_example_path('fukushima/data.sqlite')\n",
    "print(\"Using database {}\".format(database))\n",
    "\n",
    "# Identify the coordinates, label, and label orientation for the power\n",
    "# plant and selected cities as points of reference.\n",
    "CITIES = [  # (lon, lat), desc, horizontal alignment\n",
    "    [(141.0281, 37.4213), '  Daiichi Nuclear Power Plant', 'left'],\n",
    "    [(141.0125, 37.4492), 'Futaba ', 'right'],\n",
    "    [(141.0000, 37.4833), ' Namie', 'left'],\n",
    "    [(140.9836, 37.4044), ' Okuma ', 'right'],\n",
    "    [(141.0088, 37.3454), ' Tomioka', 'left']]\n",
    "\n",
    "# The coordinates our analysis will cover\n",
    "X_COORDS = (140.9, 141.3)\n",
    "Y_COORDS = (37.0, 37.83)\n",
    "\n",
    "# The city coordinates need to be normalized to our grid (whose size depends on CELLS_PER_SIDE)\n",
    "norm_x = [CELLS_PER_SIDE * ((c[0][0] - X_COORDS[0]) / (X_COORDS[1] - X_COORDS[0])) for c in CITIES]\n",
    "norm_y = [CELLS_PER_SIDE * ((c[0][1] - Y_COORDS[0]) / (Y_COORDS[1] - Y_COORDS[0])) for c in CITIES]\n",
    "\n",
    "# Create the data access object factory.\n",
    "factory = sina_sql.DAOFactory(database)\n",
    "record_handler = factory.createRecordDAO()\n",
    "relationship_handler = factory.createRelationshipDAO()\n",
    "\n",
    "# Get the ids of the experiments (which are their dates)\n",
    "dates = list(record_handler.get_all_of_type(\"exp\", ids_only=True))\n",
    "print('Database has the following dates available: {}'.format(', '.join(dates)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter the Data: Filtering Logic\n",
    "========================\n",
    "We subdivide our coordinate range (37.3-37.8, 140.9-141.4) into $cells\\_per\\_side^2$ regions and find the records whose coordinates are within each range. We separate these out based on which day each Record is associated with. We then find that Record's gcnorm (counts per sec) and average to get that cell's average for the day, and also track the total number of records per cell per day (so we know around how confident we are in that average). \n",
    "\n",
    "This cell adds the functions to memory, plus does a bit of preprocessing. The functions themselves will be called once it's time to create the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, we figure out which record ids are associated with which dates\n",
    "records_at_dates = {}\n",
    "for date in dates:\n",
    "    records_at_dates[date] = set([str(x.object_id) for x in relationship_handler.get(subject_id=date,\n",
    "                                                                                     predicate=\"contains\")])\n",
    "\n",
    "# Jupyter sometimes has an issue with the first call to plt.show(), so we make a dummy call\n",
    "plt.show()\n",
    "\n",
    "def calculate_cell(lat_min, lat_max, long_min, long_max):\n",
    "    \"\"\"\n",
    "    Calculate the avg_gcnorm and count for the cell across each day in records_at_dates.\n",
    "\n",
    "    :param lat_min: The minimum latitude of this cell (inclusive)\n",
    "    :param lat_max: The maximum latitude of this cell (exclusive)\n",
    "    :param long_min: The minimum longitude of this cell (inclusive)\n",
    "    :param long_max: The maximum longitude of this cell (exclusive)\n",
    "\n",
    "    :returns: a dictionary mapping total and average gcnorm & num samples in a cell to a day\n",
    "    \"\"\"\n",
    "    record_ids = list(record_handler.data_query(latitude=DataRange(lat_min, lat_max),\n",
    "                                                longitude=DataRange(long_min, long_max)))\n",
    "    \n",
    "    data = record_handler.get_data_for_records(record_ids, [\"gcnorm\"])\n",
    "    out = defaultdict(lambda: {\"total\": 0.0, \"count\": 0, \"average\": 0.0})\n",
    "    for id in record_ids:\n",
    "        for date in records_at_dates:\n",
    "            if id in records_at_dates[date]:\n",
    "                out[date][\"total\"] += data[id][\"gcnorm\"][\"value\"]\n",
    "                out[date][\"count\"] += 1\n",
    "                break\n",
    "    for date in records_at_dates:\n",
    "        if out[date][\"count\"] > 0:\n",
    "            out[date][\"average\"] = out[date][\"total\"] / (out[date][\"count\"])\n",
    "    return out\n",
    "\n",
    "\n",
    "print(\"Functions loaded and date mappings built!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the Graphs\n",
    "===============\n",
    "Now we divide up based on the number of cells and collect the information for each cell independently. Since we're only *reading* the underlying database, this could, in theory, be parallelized. Generating this graph may take some time; see the progress indicator beneath the code for an idea of how much is left."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_increment = (X_COORDS[1] - X_COORDS[0]) / CELLS_PER_SIDE\n",
    "x_range = [x_increment * offset + X_COORDS[0] for offset in range(CELLS_PER_SIDE)]\n",
    "y_increment = (Y_COORDS[1] - Y_COORDS[0]) / CELLS_PER_SIDE\n",
    "y_range = [y_increment * offset + Y_COORDS[0] for offset in range(CELLS_PER_SIDE)]\n",
    "\n",
    "avgs_at_date = defaultdict(lambda: np.zeros((CELLS_PER_SIDE, CELLS_PER_SIDE)))\n",
    "counts_at_date = defaultdict(lambda: np.zeros((CELLS_PER_SIDE, CELLS_PER_SIDE)))\n",
    "\n",
    "\n",
    "# This may take awhile! (around a minute for a 12*12 map)\n",
    "def gen_data():\n",
    "    \"\"\"Generate the plot, including calculating the data it contains.\"\"\"\n",
    "    cells_completed = 0\n",
    "    for x_offset, x_coord in enumerate(x_range):\n",
    "        for y_offset, y_coord in enumerate(y_range):\n",
    "            norms_at_dates = calculate_cell(lat_min=y_coord,\n",
    "                                            lat_max=y_coord + y_increment,\n",
    "                                            long_min=x_coord,\n",
    "                                            long_max=x_coord + x_increment)\n",
    "            cells_completed += 1\n",
    "            if cells_completed % CELLS_PER_SIDE == 0:\n",
    "                progress = (\"Progress: {}/{}, finished ([{},{}), [{}, {}))\"\n",
    "                            .format(cells_completed, CELLS_PER_SIDE ** 2,\n",
    "                                    '{:.3f}'.format(x_coord),\n",
    "                                    '{:.3f}'.format(x_coord + x_increment),\n",
    "                                    '{:.3f}'.format(y_coord),\n",
    "                                    '{:.3f}'.format(y_coord + y_increment)))\n",
    "                clear_output(wait=True)\n",
    "                display(progress)\n",
    "            for date in norms_at_dates:\n",
    "                avgs_at_date[date][y_offset, x_offset] = (norms_at_dates[date][\"average\"])\n",
    "                counts_at_date[date][y_offset, x_offset] = (norms_at_dates[date][\"count\"])\n",
    "\n",
    "\n",
    "gen_data()\n",
    "print(\"All cells calculated! You can now generate the graph (next cell).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configuring and Displaying the Graph\n",
    "--------------------------------------------\n",
    "\n",
    "There's a fair bit of configuration that goes into how the heatmap is displayed. Feel free to tweak these settings to maximize how readable the data is for you personally. Once you're ready (and the cell above has completed), run this cell to display the graph! You can re-run this cell after tweaking the config options to re-create your graph relatively quickly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How the cities are marked. Font/marker color and size, label outline and size\n",
    "COLOR_CITIES = 'white'\n",
    "COLOR_OUTLINE = 'black'\n",
    "SIZE_CITY_FONT = 14\n",
    "SIZE_OUTLINE = 5\n",
    "AREA_CITIES = 50\n",
    "\n",
    "# Heatmap colormap, see https://matplotlib.org/users/colormaps.html#grayscale-conversion\n",
    "COLORMAP = \"plasma\"\n",
    "\n",
    "\n",
    "def create_graph():\n",
    "    \"\"\"Configure and display the graph itself. Dependent on the data from gen_plot().\"\"\"\n",
    "    for date in dates:\n",
    "        fig, ax = plt.subplots(figsize=(9, 9))\n",
    "        plt.xlabel('Longitude')\n",
    "        plt.ylabel('Latitude')\n",
    "        heatmap_avg = ax.imshow(avgs_at_date[date], origin='lower', cmap=COLORMAP)\n",
    "        plt.colorbar(heatmap_avg, label=\"Counts Per Second\")\n",
    "        plt.title(\"Fukushima Radiation: Flight {}\".format(date))\n",
    "        _ = ax.scatter(x=norm_x,\n",
    "                       y=norm_y,\n",
    "                       s=AREA_CITIES,\n",
    "                       c=COLOR_CITIES,\n",
    "                       linewidths=SIZE_OUTLINE / 2,  # Correction to be around same size as font outline\n",
    "                       edgecolor=COLOR_OUTLINE)\n",
    "        for x_coord, y_coord, city_info in zip(norm_x, norm_y, CITIES):\n",
    "            _, desc, alignment = city_info\n",
    "            text = ax.text(x_coord, y_coord, desc,\n",
    "                           va=\"center\", ha=alignment,\n",
    "                           size=SIZE_CITY_FONT, color=COLOR_CITIES)\n",
    "            text.set_path_effects([patheffects.withStroke(linewidth=SIZE_OUTLINE,\n",
    "                                                          foreground=COLOR_OUTLINE)])\n",
    "\n",
    "        # Matplotlib labels the boxes themselves, rather than their\n",
    "        # borders/the origins, so we need to calculate the centers\n",
    "        ax.set_xticks(range(len(x_range)))\n",
    "        ax.set_xticklabels(('{:.3f}'.format(x + x_increment / 2) for x in x_range))\n",
    "        ax.set_yticks(range(len(y_range)))\n",
    "        ax.set_yticklabels(('{:.3f}'.format(y + y_increment / 2) for y in y_range))\n",
    "        plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "                 rotation_mode=\"anchor\")\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "create_graph()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sina",
   "language": "python",
   "name": "sina"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
