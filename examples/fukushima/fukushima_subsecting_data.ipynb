{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fukushima Heatmap: Subsecting Data\n",
    "===============================\n",
    "In some cases, the amount of data available is too much to graph all at once. While the Fukushima set is small enough to fit comfortably in memory, we can still use it to showcase some techniques for handling much larger sets. In this case, we will still process the entire set of data, but do so in coordinate cells; each cell is averaged to create a heatmap. You can configure the number of cells created; the more there are, the less data is held in memory at a time, but the more queries are done overall.\n",
    "\n",
    "\n",
    "Configuring the Graph\n",
    "--------------------------\n",
    "\n",
    "First, we configure the number of cells as described above. There's also a fair bit of configuration that goes into how the heatmap is displayed. Feel free to tweak these settings to maximize how readable the data is for you personally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of cells along a side; this number squared is the total number of cells\n",
    "CELLS_PER_SIDE = 12\n",
    "\n",
    "# How the cities are marked. Font/marker color and size, label outline and size\n",
    "COLOR_CITIES = 'white'\n",
    "FONT_SIZE=12\n",
    "COLOR_OUTLINE = 'black'\n",
    "OUTLINE_SIZE = 5\n",
    "AREA_CITIES = 50\n",
    "\n",
    "# Heatmap colormap, see https://matplotlib.org/users/colormaps.html#miscellaneous\n",
    "COLORMAP = \"viridis\"\n",
    "\n",
    "print('Config loaded. Re-run this cell to update how the graph is displayed.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Opening a connection and finding all dates\n",
    "--------------------------------------------------\n",
    "\n",
    "After we define our constants, we open a connection to our database of interest, and find what dates are available to us. We'll track data from each date separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sina.datastores.sql as sina_sql\n",
    "\n",
    "DATABASE = '/collab/usr/gapps/wf/examples/data/fukushima/fukushima.sqlite'\n",
    "\n",
    "# Identify the coordinates, label, and label orientation for the power\n",
    "# plant and selected cities as points of reference.\n",
    "CITIES = [  # (lon, lat), desc, horizontal alignment\n",
    "    [(141.0281, 37.4213), '  Daiichi Nuclear Power Plant', 'left'],\n",
    "    [(141.0125, 37.4492), 'Futaba ', 'right'],\n",
    "    [(141.0000, 37.4833), ' Namie', 'left'],\n",
    "    [(140.9836, 37.4044), ' Okuma ', 'right'],\n",
    "    [(141.0088, 37.3454), ' Tomioka', 'left']]\n",
    "\n",
    "# The coordinates our analysis will cover\n",
    "X_COORDS = (140.9, 141.3)\n",
    "Y_COORDS = (37.0, 37.83)\n",
    "\n",
    "# The city coordinates need to be normalized to our grid (whose size depends on CELLS_PER_SIDE)\n",
    "norm_x = [CELLS_PER_SIDE*((c[0][0]-X_COORDS[0])/(X_COORDS[1]-X_COORDS[0])) for c in CITIES]\n",
    "norm_y = [CELLS_PER_SIDE*((c[0][1]-Y_COORDS[0])/(Y_COORDS[1]-Y_COORDS[0])) for c in CITIES]\n",
    "\n",
    "# Create the data access object factory.\n",
    "factory = sina_sql.DAOFactory(DATABASE)\n",
    "record_handler = factory.createRecordDAO()\n",
    "relationship_handler = factory.createRelationshipDAO()\n",
    "\n",
    "# Get the ids of the experiments (which are their dates)\n",
    "all_experiments = record_handler.get_all_of_type(\"exp\")\n",
    "dates = [str(x.id) for x in all_experiments]\n",
    "print('Database has the following dates available: {}'.format(', '.join(dates)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter the Data: Filtering Logic\n",
    "========================\n",
    "We subdivide our coordinate range (37.3-37.8, 140.9-141.4) into $cells\\_per\\_side^2$ regions and find the records whose coordinates are within each range. We separate these out based on which day each Record is associated with. We then find that Record's gcnorm (counts per sec) and average to get that cell's average for the day, and also track the total number of records per cell per day (so we know around how confident we are in that average). \n",
    "\n",
    "This cell adds the functions to memory, plus does a bit of preprocessing. The functions themselves will be called once it's time to create the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sina.utils import ScalarRange\n",
    "from collections import defaultdict\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# First, we figure out which record ids are associated with which dates\n",
    "records_at_dates = {}\n",
    "for date in dates:\n",
    "    records_at_dates[date] = set([str(x.object_id) for x in relationship_handler.get(subject_id=date,\n",
    "                                                                                     predicate=\"contains\")])\n",
    "    \n",
    "# Jupyter sometimes has an issue with the first call to plt.show(), so we make a dummy call\n",
    "plt.show()\n",
    "\n",
    "\n",
    "def find_in_range(lat_min, lat_max, long_min, long_max):\n",
    "    \"\"\"\n",
    "    Find and return all Records in a coordinate square.\n",
    "    \n",
    "    :param lat_min: The minimum latitude a Record can have (inclusive)\n",
    "    :param lat_max: The maximum latitude a Record can have (exclusive)\n",
    "    :param long_min: The minimum longitude a Record can have (inclusive)\n",
    "    :param long_max: The maximum longitude a Record can have (exclusive)\n",
    "    \n",
    "    :returns: A list of Records within this coordinate range\n",
    "    \"\"\"\n",
    "    latitude_req = ScalarRange(name=\"latitude\",\n",
    "                               min=lat_min,\n",
    "                               min_inclusive=True,\n",
    "                               max=lat_max,\n",
    "                               max_inclusive=False)\n",
    "    longitude_req = ScalarRange(name=\"longitude\",\n",
    "                                min=long_min,\n",
    "                                min_inclusive=True,\n",
    "                                max=long_max,\n",
    "                                max_inclusive=False)\n",
    "    return record_handler.get_given_scalars((latitude_req,\n",
    "                                             longitude_req))\n",
    "    \n",
    "    \n",
    "def calculate_cell(lat_min, lat_max, long_min, long_max):\n",
    "    \"\"\"\n",
    "    Calculate the avg_gcnorm and count for the cell across each day in records_at_dates.\n",
    "    \n",
    "    :param lat_min: The minimum latitude of this cell (inclusive)\n",
    "    :param lat_max: The maximum latitude of this cell (exclusive)\n",
    "    :param long_min: The minimum longitude of this cell (inclusive)\n",
    "    :param long_max: The maximum longitude of this cell (exclusive)\n",
    "    \n",
    "    :returns: a dictionary mapping total and average gcnorm & num samples in a cell to a day\n",
    "    \"\"\"\n",
    "    records = find_in_range(lat_min, lat_max, long_min, long_max)\n",
    "    out = defaultdict(lambda: {\"total\":0.0, \"count\":0, \"average\":0.0})\n",
    "    for record in records:\n",
    "        for date in records_at_dates:\n",
    "            if record.id in records_at_dates[date]:\n",
    "                out[date][\"total\"] += record.data[\"gcnorm\"][\"value\"]\n",
    "                out[date][\"count\"] += 1\n",
    "                break\n",
    "    for date in records_at_dates:\n",
    "        if out[date][\"count\"] > 0:\n",
    "            out[date][\"average\"] = out[date][\"total\"]/(out[date][\"count\"])\n",
    "    return out\n",
    "\n",
    "print(\"Functions loaded and date mappings built!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the Graphs\n",
    "===============\n",
    "Now we divide up based on the number of cells and collect the information for each cell independently. Since we're only *reading* the underlying database, this could, in theory, be parallelized. Generating this graph may take some time; see the progress indicator beneath the code for an idea of how much is left."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import patheffects\n",
    "import numpy as np\n",
    "from IPython.display import clear_output, display\n",
    "\n",
    "x_increment = (X_COORDS[1]-X_COORDS[0])/CELLS_PER_SIDE\n",
    "x_range = [x_increment*offset+X_COORDS[0] for offset in range(CELLS_PER_SIDE)]\n",
    "y_increment = (Y_COORDS[1]-Y_COORDS[0])/CELLS_PER_SIDE\n",
    "y_range = [y_increment*offset+Y_COORDS[0] for offset in range(CELLS_PER_SIDE)]\n",
    "\n",
    "avgs_at_date = defaultdict(lambda: np.zeros((CELLS_PER_SIDE, CELLS_PER_SIDE)))\n",
    "counts_at_date = defaultdict(lambda: np.zeros((CELLS_PER_SIDE, CELLS_PER_SIDE)))\n",
    "\n",
    "# This may take awhile! (around a minute for a 12*12 map)\n",
    "def gen_plot():  \n",
    "    \"\"\"Generate the plot, including calculating the data it contains.\"\"\"\n",
    "    cells_completed = 0\n",
    "    for x_offset, x_coord in enumerate(x_range):\n",
    "        for y_offset, y_coord in enumerate(y_range):\n",
    "            norms_at_dates = calculate_cell(lat_min=y_coord,\n",
    "                                             lat_max=y_coord + y_increment,\n",
    "                                             long_min=x_coord,\n",
    "                                             long_max=x_coord + x_increment)\n",
    "            cells_completed += 1\n",
    "            progress = (\"Progress: {}/{}, finished ([{},{}), [{}, {}))\"\n",
    "                        .format(cells_completed,\n",
    "                         CELLS_PER_SIDE**2,\n",
    "                         '%.3f'%(x_coord),\n",
    "                         '%.3f'%(x_coord + x_increment),\n",
    "                         '%.3f'%(y_coord),\n",
    "                         '%.3f'%(y_coord + y_increment)))\n",
    "            clear_output(wait=True)\n",
    "            display(progress)\n",
    "            for date in norms_at_dates:\n",
    "                avgs_at_date[date][y_offset, x_offset] = (norms_at_dates[date][\"average\"])\n",
    "                counts_at_date[date][y_offset, x_offset] = (norms_at_dates[date][\"count\"])\n",
    "    create_graph()\n",
    "                \n",
    "                \n",
    "def create_graph():\n",
    "    \"\"\"\n",
    "    Configure and display the graph itself. Dependent on the data from gen_plot().\n",
    "    \n",
    "    In case you're trying different graph display configs, you may want to call this\n",
    "    instead of gen_plot(); as long as gen_plot()'s been called once in this notebook\n",
    "    instance (and the kernel hasn't restarted), the data it needs will still be in\n",
    "    memory, and calling this alone is much faster.\n",
    "    \"\"\"\n",
    "    print(\"Creating graph...\")\n",
    "    for date in dates:\n",
    "        fig, ax = plt.subplots(figsize=(9,9))\n",
    "        plt.xlabel('Longitude')\n",
    "        plt.ylabel('Latitude')\n",
    "        heatmap_avg = ax.imshow(avgs_at_date[date], origin='lower', cmap=COLORMAP)\n",
    "        plt.colorbar(heatmap_avg, label=\"Counts Per Second\")\n",
    "        plt.title(\"Fukushima Radiation: Flight {}\".format(date))\n",
    "        scatter = ax.scatter(x=norm_x,\n",
    "                             y=norm_y,\n",
    "                             s=AREA_CITIES,\n",
    "                             c=COLOR_OUTLINE)\n",
    "        scatter = ax.scatter(x=norm_x,\n",
    "                             y=norm_y,\n",
    "                             s=(AREA_CITIES/2.0),\n",
    "                             c=COLOR_CITIES)\n",
    "        for x_coord, y_coord, city_info in zip(norm_x, norm_y, CITIES):\n",
    "            _, desc, alignment = city_info\n",
    "            text = ax.text(x_coord, y_coord,desc,\n",
    "                           va=\"center\", ha=alignment,\n",
    "                           size=FONT_SIZE, color=COLOR_CITIES)\n",
    "            text.set_path_effects([patheffects.withStroke(linewidth=OUTLINE_SIZE,\n",
    "                                                          foreground=COLOR_OUTLINE)])\n",
    "\n",
    "        # Matplotlib labels the boxes themselves, rather than their\n",
    "        # borders/the origins, so we need to calculate the centers\n",
    "        ax.set_xticks(range(len(x_range)))\n",
    "        ax.set_xticklabels(('%.3f'%(x+x_increment/2) for x in x_range))\n",
    "        ax.set_yticks(range(len(y_range)))\n",
    "        ax.set_yticklabels(('%.3f'%(y+y_increment/2) for y in y_range))\n",
    "        plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "                 rotation_mode=\"anchor\")\n",
    "        \n",
    "        plt.show()\n",
    "\n",
    "gen_plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sina",
   "language": "python",
   "name": "sina"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
